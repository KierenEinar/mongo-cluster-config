2018-02-28T14:14:43.593+0800 I CONTROL  [initandlisten] MongoDB starting : pid=30729 port=28002 dbpath=/usr/local/mongo-cluster-sharding/configsvr/node2/data/db 64-bit host=kieren.local
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] db version v3.4.7
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] git version: cf38c1b8a0a8dca4a11737581beafef4fe120bcd
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 0.9.8zg 14 July 2015
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] allocator: system
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] modules: none
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] build environment:
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten]     distarch: x86_64
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten]     target_arch: x86_64
2018-02-28T14:14:43.594+0800 I CONTROL  [initandlisten] options: { config: "mongodb.conf", net: { bindIp: "127.0.0.1", port: 28002 }, processManagement: { fork: true }, replication: { replSet: "configset" }, sharding: { clusterRole: "configsvr" }, storage: { dbPath: "/usr/local/mongo-cluster-sharding/configsvr/node2/data/db" }, systemLog: { destination: "file", logAppend: true, path: "/usr/local/mongo-cluster-sharding/configsvr/node2/log/mongodb.log" } }
2018-02-28T14:14:43.594+0800 I STORAGE  [initandlisten] wiredtiger_open config: create,cache_size=3584M,session_max=20000,eviction=(threads_min=4,threads_max=4),config_base=false,statistics=(fast),log=(enabled=true,archive=true,path=journal,compressor=snappy),file_manager=(close_idle_time=100000),checkpoint=(wait=60,log_size=2GB),statistics_log=(wait=0),
2018-02-28T14:14:44.705+0800 I CONTROL  [initandlisten] 
2018-02-28T14:14:44.705+0800 I CONTROL  [initandlisten] ** WARNING: Access control is not enabled for the database.
2018-02-28T14:14:44.705+0800 I CONTROL  [initandlisten] **          Read and write access to data and configuration is unrestricted.
2018-02-28T14:14:44.705+0800 I CONTROL  [initandlisten] 
2018-02-28T14:14:44.705+0800 I CONTROL  [initandlisten] 
2018-02-28T14:14:44.705+0800 I CONTROL  [initandlisten] ** WARNING: soft rlimits too low. Number of files is 256, should be at least 1000
2018-02-28T14:14:44.904+0800 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/usr/local/mongo-cluster-sharding/configsvr/node2/data/db/diagnostic.data'
2018-02-28T14:14:44.910+0800 I SHARDING [thread1] creating distributed lock ping thread for process ConfigServer (sleeping for 30000ms)
2018-02-28T14:14:44.910+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:14:45.596+0800 I REPL     [initandlisten] Did not find local voted for document at startup.
2018-02-28T14:14:45.596+0800 I REPL     [initandlisten] Did not find local replica set configuration document at startup;  NoMatchingDocument: Did not find replica set configuration document in local.system.replset
2018-02-28T14:14:45.597+0800 I NETWORK  [thread2] waiting for connections on port 28002
2018-02-28T14:15:14.914+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:15:44.947+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:16:15.224+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:16:45.227+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:17:15.232+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:17:24.242+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49654 #1 (1 connection now open)
2018-02-28T14:17:24.245+0800 I -        [conn1] end connection 127.0.0.1:49654 (1 connection now open)
2018-02-28T14:17:24.247+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49656 #2 (1 connection now open)
2018-02-28T14:17:24.247+0800 I NETWORK  [conn2] received client metadata from 127.0.0.1:49656 conn2: { driver: { name: "NetworkInterfaceASIO-Replication", version: "3.4.7" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "15.3.0" } }
2018-02-28T14:17:24.248+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Connecting to 127.0.0.1:28001
2018-02-28T14:17:24.249+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Successfully connected to 127.0.0.1:28001, took 1ms (1 connections now open to 127.0.0.1:28001)
2018-02-28T14:17:45.271+0800 I SHARDING [shard registry reload] Periodic reload of shard registry failed  :: caused by :: 134 could not get updated shard list from config server due to Read concern majority reads are currently not possible.; will retry after 30s
2018-02-28T14:17:45.677+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49696 #3 (2 connections now open)
2018-02-28T14:17:45.677+0800 I -        [conn3] end connection 127.0.0.1:49696 (2 connections now open)
2018-02-28T14:17:46.362+0800 I REPL     [replExecDBWorker-0] Starting replication snapshot thread
2018-02-28T14:17:46.362+0800 I REPL     [replExecDBWorker-0] Starting replication storage threads
2018-02-28T14:17:46.534+0800 I REPL     [replication-0] Starting initial sync (attempt 1 of 10)
2018-02-28T14:17:46.535+0800 I REPL     [ReplicationExecutor] New replica set config in use: { _id: "configset", version: 1, configsvr: true, protocolVersion: 1, members: [ { _id: 1, host: "127.0.0.1:28001", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 2, host: "127.0.0.1:28002", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 }, { _id: 3, host: "127.0.0.1:28003", arbiterOnly: false, buildIndexes: true, hidden: false, priority: 1.0, tags: {}, slaveDelay: 0, votes: 1 } ], settings: { chainingAllowed: true, heartbeatIntervalMillis: 2000, heartbeatTimeoutSecs: 10, electionTimeoutMillis: 10000, catchUpTimeoutMillis: 60000, getLastErrorModes: {}, getLastErrorDefaults: { w: 1, wtimeout: 0 }, replicaSetId: ObjectId('5a9649899ac5bc9267871b60') } }
2018-02-28T14:17:46.535+0800 I REPL     [ReplicationExecutor] This node is 127.0.0.1:28002 in the config
2018-02-28T14:17:46.535+0800 I REPL     [ReplicationExecutor] transition to STARTUP2
2018-02-28T14:17:46.535+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Connecting to 127.0.0.1:28003
2018-02-28T14:17:46.535+0800 I REPL     [ReplicationExecutor] Member 127.0.0.1:28001 is now in state SECONDARY
2018-02-28T14:17:46.535+0800 I ASIO     [NetworkInterfaceASIO-Replication-0] Successfully connected to 127.0.0.1:28003, took 0ms (1 connections now open to 127.0.0.1:28003)
2018-02-28T14:17:46.536+0800 I REPL     [ReplicationExecutor] Member 127.0.0.1:28003 is now in state STARTUP
2018-02-28T14:17:46.536+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49703 #4 (2 connections now open)
2018-02-28T14:17:46.536+0800 I NETWORK  [conn4] received client metadata from 127.0.0.1:49703 conn4: { driver: { name: "NetworkInterfaceASIO-Replication", version: "3.4.7" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "15.3.0" } }
2018-02-28T14:17:46.537+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49705 #5 (3 connections now open)
2018-02-28T14:17:46.538+0800 I -        [conn5] end connection 127.0.0.1:49705 (3 connections now open)
2018-02-28T14:17:46.674+0800 I REPL     [replication-0] sync source candidate: 127.0.0.1:28001
2018-02-28T14:17:46.674+0800 I STORAGE  [replication-0] dropAllDatabasesExceptLocal 1
2018-02-28T14:17:46.674+0800 I REPL     [replication-0] ******
2018-02-28T14:17:46.674+0800 I REPL     [replication-0] creating replication oplog of size: 192MB...
2018-02-28T14:17:46.722+0800 I STORAGE  [replication-0] Starting WiredTigerRecordStoreThread local.oplog.rs
2018-02-28T14:17:46.722+0800 I STORAGE  [replication-0] The size storer reports that the oplog contains 0 records totaling to 0 bytes
2018-02-28T14:17:46.722+0800 I STORAGE  [replication-0] Scanning the oplog to determine where to place markers for truncation
2018-02-28T14:17:47.096+0800 I REPL     [replication-0] ******
2018-02-28T14:17:47.096+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Connecting to 127.0.0.1:28001
2018-02-28T14:17:47.097+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Successfully connected to 127.0.0.1:28001, took 1ms (1 connections now open to 127.0.0.1:28001)
2018-02-28T14:17:47.097+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Connecting to 127.0.0.1:28001
2018-02-28T14:17:47.098+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Successfully connected to 127.0.0.1:28001, took 1ms (2 connections now open to 127.0.0.1:28001)
2018-02-28T14:17:47.099+0800 I REPL     [replication-1] CollectionCloner::start called, on ns:admin.system.version
2018-02-28T14:17:47.200+0800 I INDEX    [InitialSyncInserters-admin.system.version0] build index on: admin.system.version properties: { v: 2, key: { version: 1 }, name: "incompatible_with_version_32", ns: "admin.system.version" }
2018-02-28T14:17:47.200+0800 I INDEX    [InitialSyncInserters-admin.system.version0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:17:47.243+0800 I INDEX    [InitialSyncInserters-admin.system.version0] build index on: admin.system.version properties: { v: 1, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" }
2018-02-28T14:17:47.243+0800 I INDEX    [InitialSyncInserters-admin.system.version0] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:17:47.243+0800 I COMMAND  [InitialSyncInserters-admin.system.version0] setting featureCompatibilityVersion to 3.4
2018-02-28T14:17:47.296+0800 I REPL     [replication-1] No need to apply operations. (currently at { : Timestamp 1519798665000|1 })
2018-02-28T14:17:47.296+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Ending connection to host 127.0.0.1:28001 due to bad connection status; 1 connections to that host remain open
2018-02-28T14:17:47.296+0800 I REPL     [replication-1] Finished fetching oplog during initial sync: CallbackCanceled: Callback canceled. Last fetched optime and hash: { ts: Timestamp 1519798665000|1, t: -1 }[-8629422867872974848]
2018-02-28T14:17:47.296+0800 I REPL     [replication-1] Initial sync attempt finishing up.
2018-02-28T14:17:47.297+0800 I REPL     [replication-1] Initial Sync Attempt Statistics: { failedInitialSyncAttempts: 0, maxFailedInitialSyncAttempts: 10, initialSyncStart: new Date(1519798666534), initialSyncAttempts: [], fetchedMissingDocs: 0, appliedOps: 0, initialSyncOplogStart: Timestamp 1519798665000|1, initialSyncOplogEnd: Timestamp 1519798665000|1, databases: { databasesCloned: 1, admin: { collections: 1, clonedCollections: 1, start: new Date(1519798667098), end: new Date(1519798667296), elapsedMillis: 198, admin.system.version: { documentsToCopy: 1, documentsCopied: 1, indexes: 2, fetchedBatches: 1, start: new Date(1519798667099), end: new Date(1519798667296), elapsedMillis: 197 } } } }
2018-02-28T14:17:47.363+0800 I REPL     [replication-0] initial sync done; took 0s.
2018-02-28T14:17:47.363+0800 I REPL     [replication-0] Starting replication fetcher thread
2018-02-28T14:17:47.363+0800 I REPL     [replication-0] Starting replication applier thread
2018-02-28T14:17:47.364+0800 I REPL     [rsBackgroundSync] could not find member to sync from
2018-02-28T14:17:47.364+0800 I REPL     [replication-0] Starting replication reporter thread
2018-02-28T14:17:47.364+0800 I REPL     [rsSync] transition to RECOVERING
2018-02-28T14:17:47.364+0800 I REPL     [ReplicationExecutor] Member 127.0.0.1:28003 is now in state STARTUP2
2018-02-28T14:17:47.365+0800 I REPL     [rsSync] transition to SECONDARY
2018-02-28T14:17:52.369+0800 I REPL     [ReplicationExecutor] Member 127.0.0.1:28003 is now in state SECONDARY
2018-02-28T14:17:57.483+0800 I COMMAND  [conn2] command local.replset.election command: replSetRequestVotes { replSetRequestVotes: 1, setName: "configset", dryRun: false, term: 1, candidateIndex: 0, configVersion: 1, lastCommittedOp: { ts: Timestamp 1519798665000|1, t: -1 } } numYields:0 reslen:123 locks:{ Global: { acquireCount: { r: 4, w: 2 } }, Database: { acquireCount: { r: 1, W: 2 } }, Collection: { acquireCount: { r: 1 } } } protocol:op_command 111ms
2018-02-28T14:18:02.371+0800 I REPL     [ReplicationExecutor] Member 127.0.0.1:28001 is now in state PRIMARY
2018-02-28T14:18:02.484+0800 I REPL     [rsBackgroundSync] sync source candidate: 127.0.0.1:28001
2018-02-28T14:18:02.484+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Connecting to 127.0.0.1:28001
2018-02-28T14:18:02.485+0800 I ASIO     [NetworkInterfaceASIO-RS-0] Successfully connected to 127.0.0.1:28001, took 1ms (2 connections now open to 127.0.0.1:28001)
2018-02-28T14:18:02.595+0800 I INDEX    [repl writer worker 5] build index on: config.chunks properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.chunks" }
2018-02-28T14:18:02.595+0800 I INDEX    [repl writer worker 5] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:02.606+0800 I INDEX    [repl writer worker 5] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:02.640+0800 I INDEX    [repl writer worker 6] build index on: config.chunks properties: { v: 2, unique: true, key: { ns: 1, shard: 1, min: 1 }, name: "ns_1_shard_1_min_1", ns: "config.chunks" }
2018-02-28T14:18:02.640+0800 I INDEX    [repl writer worker 6] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:02.651+0800 I INDEX    [repl writer worker 6] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:02.662+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49744 #6 (3 connections now open)
2018-02-28T14:18:02.662+0800 I NETWORK  [conn6] received client metadata from 127.0.0.1:49744 conn6: { driver: { name: "NetworkInterfaceASIO-RS", version: "3.4.7" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "15.3.0" } }
2018-02-28T14:18:02.692+0800 I INDEX    [repl writer worker 8] build index on: config.chunks properties: { v: 2, unique: true, key: { ns: 1, lastmod: 1 }, name: "ns_1_lastmod_1", ns: "config.chunks" }
2018-02-28T14:18:02.692+0800 I INDEX    [repl writer worker 8] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:02.703+0800 I INDEX    [repl writer worker 8] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:02.704+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:49745 #7 (4 connections now open)
2018-02-28T14:18:02.704+0800 I NETWORK  [conn7] received client metadata from 127.0.0.1:49745 conn7: { driver: { name: "NetworkInterfaceASIO-RS", version: "3.4.7" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "15.3.0" } }
2018-02-28T14:18:02.813+0800 I INDEX    [repl writer worker 14] build index on: config.migrations properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.migrations" }
2018-02-28T14:18:02.813+0800 I INDEX    [repl writer worker 14] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:02.834+0800 I INDEX    [repl writer worker 14] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:02.947+0800 I COMMAND  [conn6] command local.oplog.rs command: getMore { getMore: 38365065399, collection: "oplog.rs", maxTimeMS: 5000, term: 1, lastKnownCommittedOpTime: { ts: Timestamp 1519798679000|6, t: 1 } } originatingCommand: { find: "oplog.rs", filter: { ts: { $gte: Timestamp 1519798665000|1 } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 60000, term: 1 } planSummary: COLLSCAN cursorid:38365065399 keysExamined:0 docsExamined:1 numYields:0 nreturned:1 reslen:694 locks:{ Global: { acquireCount: { r: 2 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 110534 } }, Database: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } protocol:op_command 110ms
2018-02-28T14:18:02.996+0800 I INDEX    [repl writer worker 1] build index on: config.shards properties: { v: 2, unique: true, key: { host: 1 }, name: "host_1", ns: "config.shards" }
2018-02-28T14:18:02.996+0800 I INDEX    [repl writer worker 1] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:03.030+0800 I INDEX    [repl writer worker 1] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:03.154+0800 I COMMAND  [conn6] command local.oplog.rs command: getMore { getMore: 38365065399, collection: "oplog.rs", maxTimeMS: 5000, term: 1, lastKnownCommittedOpTime: { ts: Timestamp 1519798679000|8, t: 1 } } originatingCommand: { find: "oplog.rs", filter: { ts: { $gte: Timestamp 1519798665000|1 } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 60000, term: 1 } planSummary: COLLSCAN cursorid:38365065399 keysExamined:0 docsExamined:1 numYields:0 nreturned:1 reslen:692 locks:{ Global: { acquireCount: { r: 2 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 120596 } }, Database: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } protocol:op_command 120ms
2018-02-28T14:18:03.245+0800 I INDEX    [repl writer worker 5] build index on: config.locks properties: { v: 2, key: { ts: 1 }, name: "ts_1", ns: "config.locks" }
2018-02-28T14:18:03.245+0800 I INDEX    [repl writer worker 5] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:03.269+0800 I INDEX    [repl writer worker 5] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:03.269+0800 I COMMAND  [conn6] command local.oplog.rs command: getMore { getMore: 38365065399, collection: "oplog.rs", maxTimeMS: 5000, term: 1, lastKnownCommittedOpTime: { ts: Timestamp 1519798679000|9, t: 1 } } originatingCommand: { find: "oplog.rs", filter: { ts: { $gte: Timestamp 1519798665000|1 } }, tailable: true, oplogReplay: true, awaitData: true, maxTimeMS: 60000, term: 1 } planSummary: COLLSCAN cursorid:38365065399 keysExamined:0 docsExamined:1 numYields:0 nreturned:1 reslen:669 locks:{ Global: { acquireCount: { r: 2 }, acquireWaitCount: { r: 1 }, timeAcquiringMicros: { r: 111636 } }, Database: { acquireCount: { r: 1 } }, oplog: { acquireCount: { r: 1 } } } protocol:op_command 111ms
2018-02-28T14:18:03.307+0800 I INDEX    [repl writer worker 6] build index on: config.locks properties: { v: 2, key: { state: 1, process: 1 }, name: "state_1_process_1", ns: "config.locks" }
2018-02-28T14:18:03.307+0800 I INDEX    [repl writer worker 6] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:03.329+0800 I INDEX    [repl writer worker 6] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:03.470+0800 I INDEX    [repl writer worker 9] build index on: config.lockpings properties: { v: 2, key: { ping: 1 }, name: "ping_1", ns: "config.lockpings" }
2018-02-28T14:18:03.470+0800 I INDEX    [repl writer worker 9] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:03.501+0800 I INDEX    [repl writer worker 9] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:03.656+0800 I INDEX    [repl writer worker 15] build index on: config.tags properties: { v: 2, unique: true, key: { ns: 1, min: 1 }, name: "ns_1_min_1", ns: "config.tags" }
2018-02-28T14:18:03.657+0800 I INDEX    [repl writer worker 15] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:03.676+0800 I INDEX    [repl writer worker 15] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:18:03.716+0800 I INDEX    [repl writer worker 1] build index on: config.tags properties: { v: 2, key: { ns: 1, tag: 1 }, name: "ns_1_tag_1", ns: "config.tags" }
2018-02-28T14:18:03.716+0800 I INDEX    [repl writer worker 1] 	 building index using bulk method; build may temporarily use up to 500 megabytes of RAM
2018-02-28T14:18:03.736+0800 I INDEX    [repl writer worker 1] build index done.  scanned 0 total records. 0 secs
2018-02-28T14:22:06.604+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:50165 #8 (5 connections now open)
2018-02-28T14:22:06.636+0800 I NETWORK  [conn8] received client metadata from 127.0.0.1:50165 conn8: { driver: { name: "MongoDB Internal Client", version: "3.4.7" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "15.3.0" } }
2018-02-28T14:22:08.610+0800 I NETWORK  [thread2] connection accepted from 127.0.0.1:50176 #9 (6 connections now open)
2018-02-28T14:22:08.610+0800 I NETWORK  [conn9] received client metadata from 127.0.0.1:50176 conn9: { driver: { name: "NetworkInterfaceASIO-ShardRegistry", version: "3.4.7" }, os: { type: "Darwin", name: "Mac OS X", architecture: "x86_64", version: "15.3.0" } }
2018-02-28T14:24:45.335+0800 I NETWORK  [shard registry reload] Starting new replica set monitor for set1/127.0.0.1:27001,127.0.0.1:27002,127.0.0.1:27003
2018-02-28T14:24:45.368+0800 I NETWORK  [shard registry reload] Starting new replica set monitor for set2/127.0.0.1:27004,127.0.0.1:27005,127.0.0.1:27006
2018-02-28T14:24:45.369+0800 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to 127.0.0.1:27002 (1 connections now open to 127.0.0.1:27002 with a 5 second timeout)
2018-02-28T14:24:45.370+0800 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to 127.0.0.1:27001 (1 connections now open to 127.0.0.1:27001 with a 5 second timeout)
2018-02-28T14:24:45.370+0800 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to 127.0.0.1:27003 (1 connections now open to 127.0.0.1:27003 with a 5 second timeout)
2018-02-28T14:24:45.371+0800 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to 127.0.0.1:27005 (1 connections now open to 127.0.0.1:27005 with a 5 second timeout)
2018-02-28T14:24:45.371+0800 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to 127.0.0.1:27004 (1 connections now open to 127.0.0.1:27004 with a 5 second timeout)
2018-02-28T14:24:45.372+0800 I NETWORK  [ReplicaSetMonitor-TaskExecutor-0] Successfully connected to 127.0.0.1:27006 (1 connections now open to 127.0.0.1:27006 with a 5 second timeout)
